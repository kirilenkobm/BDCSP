{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check, whether the results depend on shuffling\n",
    "# test on the smallest set\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import statistics\n",
    "\n",
    "DATASET_DIR = \"../tests/input_files/test_100_25_25/\"\n",
    "TEMP_DIR = \"temp\"\n",
    "DATASET_FILES = os.listdir(DATASET_DIR)\n",
    "ANSWER = 25\n",
    "STRNUM = 25\n",
    "STRLEN = 100\n",
    "os.mkdir(TEMP_DIR) if not os.path.isdir(TEMP_DIR) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create shuffled files\n",
    "rep_files = []\n",
    "der_to_orig = {}\n",
    "\n",
    "\n",
    "print(\"Overall {} files in the dataset\".format(len(DATASET_FILES)))\n",
    "task_size = len(DATASET_FILES)\n",
    "for num, to_check in enumerate(DATASET_FILES):\n",
    "    # to_check = random.choice(DATASET_FILES)\n",
    "    to_check_path = os.path.join(DATASET_DIR, to_check)\n",
    "    replicate_min = {}  # number of replicate -> minimal answer\n",
    "    \n",
    "    shuffle_cmd_templ = \"../shuffle_input.py \" + to_check_path + \" {} -o {} -c\"\n",
    "    for i in range(STRNUM):\n",
    "        out_file = os.path.join(TEMP_DIR, \"rep_{}_{}.txt\".format(num, i))\n",
    "        \n",
    "        shuffle_cmd = shuffle_cmd_templ.format(i, out_file)\n",
    "        rc = subprocess.call(shuffle_cmd, shell=True)\n",
    "        if rc != 0:\n",
    "            continue\n",
    "        rep_files.append(out_file)\n",
    "        der_to_orig[out_file] = to_check_path\n",
    "    print(\"{}/{}\".format(num + 1, task_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call CSP for each file\n",
    "# a long stage\n",
    "csp_cmd_templ = \"../CSP {} {} -v 1\"\n",
    "print(\"Overall {} files to go\".format(len(rep_files)))\n",
    "\n",
    "orig_to_files_and_k = defaultdict(list)\n",
    "\n",
    "\n",
    "for num, rep in enumerate(rep_files):\n",
    "    # get the minimal answer for each\n",
    "    csp_cmd = csp_cmd_templ.format(rep, ANSWER)\n",
    "    csp_out = subprocess.check_output(csp_cmd, shell=True).decode(\"utf-8\").split(\"\\n\")\n",
    "    answ = csp_out[-3]\n",
    "    if answ == \"True\":\n",
    "        res_ = ANSWER\n",
    "    else:\n",
    "        max_cov_line = csp_out[-5].split()\n",
    "        exp = int(max_cov_line[-1])\n",
    "        real = int(max_cov_line[-3])\n",
    "        diff = exp - real\n",
    "        res_ = ANSWER + diff\n",
    "    orig_ = der_to_orig[rep]\n",
    "    replicate_min[num] = res_\n",
    "    point = (rep, res_)\n",
    "    orig_to_files_and_k[orig_].append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize it\n",
    "min_times = Counter()\n",
    "for v in replicate_min.values():\n",
    "    min_times[v] += 1\n",
    "times_sort = sorted(min_times.keys())\n",
    "for t in range(times_sort[0], times_sort[-1] + 1):\n",
    "    app_ = min_times.get(t) if min_times.get(t) else 0\n",
    "    print(\"{}:\\n{}\".format(t, \"*\" * app_))\n",
    "# defenitely, algorithm is init string - dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe get some statistics?\n",
    "# bunch of features\n",
    "bests = []\n",
    "reps = []\n",
    "ks = []\n",
    "l_nums = []\n",
    "maxes = []\n",
    "mins = []\n",
    "deltas = []\n",
    "aves = []\n",
    "medians = []\n",
    "stds = []\n",
    "rep_best_line = defaultdict(set)\n",
    "rep_line_p_sizes = defaultdict(list)\n",
    "orig_done = set()\n",
    "pat_sizes_arrs = []\n",
    "pat_sizes_arr_means = []\n",
    "pat_sizes_arr_medians = []\n",
    "pat_arr_maxes = []\n",
    "pat_arr_mins = []\n",
    "pat_arr_stds = []\n",
    "\n",
    "\n",
    "# analyze original file\n",
    "for num, (k, v) in enumerate(orig_to_files_and_k.items()):\n",
    "    v_sorted = sorted(v, key=lambda x: x[1])\n",
    "    best_val = v_sorted[0][1]\n",
    "    \n",
    "    best_files = [x[0] for x in v_sorted if x[1] == best_val]\n",
    "    for fle in best_files:\n",
    "        best_file_info = fle.split(\"_\")\n",
    "        fle_num = int(best_file_info[1])\n",
    "        line_num = int(best_file_info[2].split(\".\")[0])\n",
    "        rep_best_line[fle_num].add(line_num)\n",
    "    \n",
    "    # work with original file\n",
    "    f = open(k, \"r\")\n",
    "    lines = [x[:-1] for x in f.readlines()]\n",
    "    f.close()\n",
    "    str_len = len(lines[0])\n",
    "    str_num = len(lines)\n",
    "    for i in range(str_len):\n",
    "        column = [int(line[i]) for line in lines]\n",
    "        zero_strings = [n for n, v in enumerate(column) if v == 0]\n",
    "        one_strings = [n for n, v in enumerate(column) if v == 0]\n",
    "        zero_pat_size = len(zero_strings)\n",
    "        one_pat_size = len(one_strings)\n",
    "        for elem in zero_strings:\n",
    "            rep_line_p_sizes[(fle_num, elem)].append(zero_pat_size)\n",
    "        for elem in one_strings:\n",
    "            rep_line_p_sizes[(fle_num, elem)].append(one_pat_size)\n",
    "    \n",
    "# put everything in lists\n",
    "for num, rep in enumerate(rep_files):\n",
    "    # get the minimal answer for each\n",
    "    fle_data = rep.split(\"_\")\n",
    "    fle_num = int(fle_data[1])\n",
    "\n",
    "    l_num = int(fle_data[2].split(\".\")[0])\n",
    "    l_nums.append(l_num)\n",
    "\n",
    "    is_best = l_num in rep_best_line[fle_num]\n",
    "    bests.append(is_best)\n",
    "\n",
    "    pat_sizes_arr = rep_line_p_sizes[(fle_num, l_num)]\n",
    "    pat_sizes_arrs.append(pat_sizes_arr)\n",
    "\n",
    "    pat_sizes_arr_means.append(statistics.mean(pat_sizes_arr))\n",
    "    pat_sizes_arr_medians.append(statistics.median(pat_sizes_arr))\n",
    "    pat_arr_stds.append(statistics.stdev(pat_sizes_arr))\n",
    "    \n",
    "    \n",
    "    pat_arr_maxes.append(max(pat_sizes_arr))\n",
    "    pat_arr_mins.append(min(pat_sizes_arr))\n",
    "\n",
    "\n",
    "    f = open(rep, \"r\")\n",
    "    lines = [l[:-1] for l in f.readlines()]\n",
    "    f.close()\n",
    "\n",
    "    k = replicate_min[num]\n",
    "    ks.append(k)\n",
    "\n",
    "    zeros = sorted([line.count(\"0\") for line in lines])\n",
    "    max_zeros = zeros[-1]\n",
    "    min_zeros = zeros[1]  # because in 0 -> 0\n",
    "    maxes.append(max_zeros)\n",
    "    mins.append(min_zeros)\n",
    "\n",
    "    delta = max_zeros - min_zeros\n",
    "    deltas.append(delta)\n",
    "\n",
    "    aves.append(statistics.mean(zeros))\n",
    "    medians.append(statistics.median(zeros))\n",
    "    stds.append(statistics.stdev(zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another visualisation?\n",
    "fig = plt.figure(figsize=(30, 40))\n",
    "rows = 4\n",
    "cols = 3\n",
    "\n",
    "mean_mean = statistics.mean(aves)\n",
    "mean_std = statistics.mean(stds)\n",
    "mean_delta = statistics.mean(deltas)\n",
    "mean_pmax_size = statistics.mean(pat_arr_maxes)\n",
    "mean_pmin_size = statistics.mean(pat_arr_mins)\n",
    "mean_pat_arr_stdevs = statistics.mean(pat_arr_stds)\n",
    "mean_pat_arr_mean = statistics.mean(pat_sizes_arr_means)\n",
    "\n",
    "med_mean = statistics.median(aves)\n",
    "med_std = statistics.median(stds)\n",
    "med_delta = statistics.median(deltas)\n",
    "med_pmax_size = statistics.median(pat_arr_maxes)\n",
    "med_pmin_size = statistics.median(pat_arr_mins)\n",
    "med_pat_arr_stdevs = statistics.median(pat_arr_stds)\n",
    "med_pat_arr_mean = statistics.mean(pat_sizes_arr_means)\n",
    "\n",
    "datasets = [maxes, mins, deltas, \n",
    "            aves, stds, pat_sizes_arr_means,\n",
    "            pat_sizes_arr_medians, pat_arr_maxes, pat_arr_mins,\n",
    "            pat_arr_stds, medians, bests]\n",
    "\n",
    "names = [\"Max_zeros\", \"Min_zeros\", \"Min_max_delta\",\n",
    "         \"Mean\", \"Std\", \"pat_arr_mean\",\n",
    "         \"pat_arr_med\", \"pat_arr_max\", \"pat_arr_mins\",\n",
    "         \"pat_arr_stdevs\", \"median\", \"is_best\"]\n",
    "\n",
    "colors = [\"red\", \"green\", \"blue\",\n",
    "          \"magenta\", \"cyan\", \"#555555\",\n",
    "          \"orange\", \"navy\", \"lightgreen\",\n",
    "          \"red\", \"green\", \"blue\"]\n",
    "\n",
    "assert(len(datasets) == len(names) == len(colors))  # just in case\n",
    "\n",
    "for num, data in enumerate(zip(datasets, names, colors), 1):\n",
    "    ax = fig.add_subplot(rows, cols, num)\n",
    "    ax.scatter(ks, data[0], s=20, color=data[2])\n",
    "    # ax.scatter(bests, data[0], s=20, color=data[2])\n",
    "    ax.set_xlabel(\"K\")\n",
    "    ax.set_ylabel(data[1])\n",
    "    ax.grid(which=\"both\")\n",
    "    if data[1] == \"Mean\":\n",
    "        ax.axhline(y=mean_mean, color='r', linestyle='-')\n",
    "        ax.axhline(y=med_mean, color='g', linestyle='-')\n",
    "    elif data[1] == \"Std\":\n",
    "        ax.axhline(y=mean_std, color='r', linestyle='-')\n",
    "        ax.axhline(y=med_std, color='g', linestyle='-')\n",
    "    elif data[1] == \"Min_max_delta\":\n",
    "        ax.axhline(y=mean_delta, color='r', linestyle='-')\n",
    "        ax.axhline(y=med_delta, color='g', linestyle='-')\n",
    "    elif data[1] == \"pat_arr_max\":\n",
    "        ax.axhline(y=mean_pmax_size, color='r', linestyle='-')\n",
    "        ax.axhline(y=med_pmax_size, color='g', linestyle='-')\n",
    "    elif data[1] == \"pat_arr_mins\":\n",
    "        ax.axhline(y=mean_pmin_size, color='r', linestyle='-')\n",
    "        ax.axhline(y=med_pmin_size, color='g', linestyle='-')\n",
    "    elif data[1] == \"pat_arr_stdevs\":\n",
    "        ax.axhline(y=mean_pat_arr_stdevs, color='r', linestyle='-')\n",
    "        ax.axhline(y=med_pat_arr_stdevs, color='g', linestyle='-')\n",
    "    elif data[1] == \"pat_arr_mean\":\n",
    "        ax.axhline(y=mean_pat_arr_mean, color='r', linestyle='-')\n",
    "        ax.axhline(y=med_pat_arr_mean, color='g', linestyle='-')\n",
    "plt.savefig(\"plots/shuffle_params.svg\")\n",
    "plt.show()\n",
    "# somehow depends on max zeros and delta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ks, worse_ks = [], []\n",
    "for elem in zip(bests, ks):\n",
    "    if elem[0]:\n",
    "        best_ks.append(elem[1])\n",
    "    else:\n",
    "        worse_ks.append(elem[1])\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "ax_1 = fig.add_subplot(1, 1, 1)\n",
    "bins = 10\n",
    "ax_1.hist(best_ks, color=\"blue\", bins=bins, alpha=0.5)\n",
    "ax_1.hist(worse_ks, color=\"red\", bins=bins, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(TEMP_DIR) if os.path.isdir(TEMP_DIR) else None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
