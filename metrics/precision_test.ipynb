{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate the error\n",
    "# negative error never happens\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from datetime import datetime as dt\n",
    "import statistics\n",
    "from numpy import linspace\n",
    "\n",
    "DATASETS_DIR = \"../tests/input_files/\"\n",
    "# different sets for precision and performance tests\n",
    "DATASETS =['test_100_25_15', 'test_100_25_25', 'test_100_25_35', 'test_100_25_50',\n",
    "           'test_100_25_75', 'test_100_50_15', 'test_100_50_25', 'test_100_50_35',\n",
    "           'test_100_50_50', 'test_100_50_75']\n",
    "# DATASETS = os.listdir(DATASETS_DIR)\n",
    "print(DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run and collect data\n",
    "CMD_TEMPL = \"../CSP {} {} -v 1\"\n",
    "dataset_data = {}\n",
    "t0 = dt.now()\n",
    "\n",
    "def get_answer(ans, filename, f=None, z=None):\n",
    "    \"\"\"Get the smallest program answer.\"\"\"\n",
    "    cmd = CMD_TEMPL.format(filename, ans)\n",
    "    if z:\n",
    "        cmd += \" -z\"\n",
    "    if f:\n",
    "        cmd += \" -f\"\n",
    "    csp_out = subprocess.check_output(cmd, shell=True).decode(\"utf-8\").split(\"\\n\")\n",
    "    if \"True\" in csp_out:\n",
    "        # ok, solved\n",
    "        return ans\n",
    "    max_cov = 0\n",
    "    req_cov = 0\n",
    "    for line in csp_out:\n",
    "        line_data = line.split()\n",
    "        if line.startswith(\"Maximal coverage found is\"):\n",
    "            max_cov = int(line_data[-3])\n",
    "            req_cov = int(line_data[-1])\n",
    "            return ans + req_cov - max_cov\n",
    "        if line.startswith(\"# Cannot find initial move\"):\n",
    "            return 100\n",
    "            \n",
    "\n",
    "datasets_num = len(DATASETS)\n",
    "for num, dataset in enumerate(DATASETS):\n",
    "    t_d0 = dt.now()\n",
    "    dataset_metadata = dataset.split(\"_\")\n",
    "    str_len = int(dataset_metadata[1])\n",
    "    str_num = int(dataset_metadata[2])\n",
    "    answer = int(dataset_metadata[3])\n",
    "    dataset_data[num] = {\"answers_0\": [],\n",
    "                         \"answers_f\": [],\n",
    "                         \"answers_z\": [],\n",
    "                         \"answers_zf\": [],\n",
    "                         \"data\": {\"str_len\": str_len,\n",
    "                                  \"str_num\": str_num,\n",
    "                                  \"answer\": answer}}\n",
    "    dataset_dir = os.path.join(DATASETS_DIR, dataset)\n",
    "    contents = os.listdir(dataset_dir)\n",
    "    for fnum, fle in enumerate(contents):\n",
    "        f_path = os.path.join(dataset_dir, fle)\n",
    "\n",
    "        k_0 = get_answer(answer, f_path)\n",
    "        k_f = get_answer(answer, f_path, f=True)\n",
    "        k_z = get_answer(answer, f_path, z=True)\n",
    "        k_zf = get_answer(answer, f_path, z=True, f=True)\n",
    "        if not k_0 or not k_f or not k_z or not k_zf:\n",
    "            print(f_path)\n",
    "\n",
    "        dataset_data[num][\"answers_0\"].append(k_0)\n",
    "        dataset_data[num][\"answers_f\"].append(k_f)\n",
    "        dataset_data[num][\"answers_z\"].append(k_z)\n",
    "        dataset_data[num][\"answers_zf\"].append(k_zf)\n",
    "    print(f\"Dataset {num + 1} / {datasets_num} done in {dt.now() - t_d0}\")\n",
    "\n",
    "print(f\"Time spent: {dt.now() - t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare answers with and without F flag\n",
    "all_answers = []\n",
    "all_f_answers = []\n",
    "all_b_answers = []\n",
    "\n",
    "fig = plt.figure(figsize=(24, 7))\n",
    "ax_1 = fig.add_subplot(1, 3, 1)\n",
    "ax_2 = fig.add_subplot(1, 3, 2)\n",
    "ax_3 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "for k, v in dataset_data.items():\n",
    "    ax_1.scatter(v[\"answers_0\"], v[\"answers_f\"], s=15)\n",
    "    ax_2.scatter(v[\"answers_0\"], v[\"answers_z\"], s=15)\n",
    "    ax_3.scatter(v[\"answers_0\"], v[\"answers_zf\"], s=15)\n",
    "\n",
    "x = linspace(*ax_1.get_xlim())\n",
    "ax_1.plot(x, x, \"--\", color=\"black\", alpha=0.5)\n",
    "ax_1.set_xlabel(\"Answer without correction\")\n",
    "ax_1.set_ylabel(\"Answer with correction F\")\n",
    "ax_1.grid()\n",
    "\n",
    "x = linspace(*ax_2.get_xlim())\n",
    "ax_2.plot(x, x, \"--\", color=\"black\", alpha=0.5)\n",
    "ax_2.set_xlabel(\"Answer without correction\")\n",
    "ax_2.set_ylabel(\"Answer with correction Z\")\n",
    "ax_2.grid()\n",
    "\n",
    "x = linspace(*ax_3.get_xlim())\n",
    "ax_3.plot(x, x, \"--\", color=\"black\", alpha=0.5)\n",
    "ax_3.set_xlabel(\"Answer without correction\")\n",
    "ax_3.set_ylabel(\"Answer with corrections Z and F\")\n",
    "ax_3.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the error\n",
    "for k, v in dataset_data.items():\n",
    "    v[\"errors_zf\"] = [a - v[\"data\"][\"answer\"] for a in v[\"answers_zf\"]]\n",
    "    v[\"errors_z\"] = [a - v[\"data\"][\"answer\"] for a in v[\"answers_z\"]]\n",
    "    v[\"errors_f\"] = [a - v[\"data\"][\"answer\"] for a in v[\"answers_f\"]]\n",
    "    v[\"errors_0\"] = [a - v[\"data\"][\"answer\"] for a in v[\"answers_0\"]]\n",
    "\n",
    "ERR_LIM = 25  # ignore errors > 25% for better plotting\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "to_plot = []\n",
    "titles = []\n",
    "\n",
    "perc_errors_0 = []\n",
    "perc_errors_f = []\n",
    "perc_errors_z = []\n",
    "perc_errors_zf = []\n",
    "answers = []\n",
    "\n",
    "for num, (k, v) in enumerate(dataset_data.items(), 1):\n",
    "    # ax = fig.add_subplot(rows, cols, num)\n",
    "    ans = v[\"data\"][\"answer\"]\n",
    "    ans_arr = [ans for _ in range(len(v[\"errors_0\"]))]\n",
    "    answers.extend(ans_arr)\n",
    "\n",
    "    perc_error_0 = [e / ans * 100 if e / ans * 100 < ERR_LIM else ERR_LIM for e in v[\"errors_0\"]]\n",
    "    perc_error_f = [e / ans * 100 if e / ans * 100 < ERR_LIM else ERR_LIM for e in v[\"errors_f\"]]\n",
    "    perc_error_z = [e / ans * 100 if e / ans * 100 < ERR_LIM else ERR_LIM for e in v[\"errors_z\"]]\n",
    "    perc_error_zf = [e / ans * 100 if e / ans * 100 < ERR_LIM else ERR_LIM for e in v[\"errors_zf\"]]\n",
    "\n",
    "    perc_errors_0.extend(perc_error_0)\n",
    "    perc_errors_f.extend(perc_error_f)\n",
    "    perc_errors_z.extend(perc_error_z)\n",
    "    perc_errors_zf.extend(perc_error_zf)\n",
    "\n",
    "    to_plot.append(perc_error_0)\n",
    "    to_plot.append(perc_error_f)\n",
    "    to_plot.append(perc_error_z)\n",
    "    to_plot.append(perc_error_zf)\n",
    "\n",
    "    title = \"{} {} {}\".format(v[\"data\"][\"str_len\"], v[\"data\"][\"str_num\"], ans)\n",
    "    titles.append(title)\n",
    "    titles.append(title + \" F\")\n",
    "    titles.append(title + \"Z\")\n",
    "    titles.append(title + \"ZF\")\n",
    "\n",
    "ax_1 = fig.add_subplot(1, 1, 1)\n",
    "pos = list(range(1, len(titles) + 1))\n",
    "vp = ax_1.violinplot(to_plot, pos,\n",
    "                     showmeans=True,\n",
    "                     showextrema=True,\n",
    "                     showmedians=True)\n",
    "\n",
    "ax_1.set_title(\"Errors with and without a correction\")\n",
    "ax_1.set_ylabel(\"Error %\")\n",
    "ax_1.axhline(y=25, color='r', linestyle='-')\n",
    "ax_1.set_xticks(pos)\n",
    "ax_1.set_xticklabels(titles, rotation=45, fontsize=8)\n",
    "ax_1.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "\n",
    "colors = [\"navy\", \"navy\", \"navy\", \"navy\",\n",
    "          \"purple\", \"purple\", \"purple\", \"purple\",\n",
    "          \"orange\", \"orange\", \"orange\", \"orange\",\n",
    "          \"green\", \"green\", \"green\", \"green\",\n",
    "          \"pink\", \"pink\", \"pink\", \"pink\",\n",
    "          ] * 2\n",
    "vp[\"cmeans\"].set_edgecolor(\"blue\")\n",
    "vp[\"cmedians\"].set_edgecolor(\"green\")\n",
    "vp[\"cbars\"].set_edgecolor(\"grey\")\n",
    "vp[\"cmaxes\"].set_edgecolor(\"grey\")\n",
    "vp[\"cmins\"].set_edgecolor(\"grey\")\n",
    "\n",
    "for vb, color in zip(vp['bodies'], colors):\n",
    "    vb.set_facecolor(color)\n",
    "    vb.set_edgecolor(\"grey\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean uncorr error: \", statistics.mean(perc_errors_0))\n",
    "print(\"Median uncorr error: \", statistics.median(perc_errors_0))\n",
    "print(\"Mean corr F error: \", statistics.mean(perc_errors_f))\n",
    "print(\"Median corr F error: \", statistics.median(perc_errors_f))\n",
    "print(\"Mean corr Z error: \", statistics.mean(perc_errors_z))\n",
    "print(\"Median corr Z error: \", statistics.median(perc_errors_z))\n",
    "print(\"Mean corr ZF error: \", statistics.mean(perc_errors_zf))\n",
    "print(\"Median corr ZF error: \", statistics.median(perc_errors_zf))\n",
    "# errors > 25% are to be TOO MUCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_err = perc_errors_f.count(0)\n",
    "print(f\"No errors: {no_err} measurements\")\n",
    "print(f\"Errors in: {len(perc_errors_f) - no_err} measurements\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
