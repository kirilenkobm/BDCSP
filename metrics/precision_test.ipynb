{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate the error\n",
    "# negative error never happens\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import statistics\n",
    "from numpy import linspace\n",
    "\n",
    "DATASETS_DIR = \"../tests/input_files/\"\n",
    "# different sets for precision and performance tests\n",
    "DATASETS = ['test_100_25_15', 'test_100_25_25', 'test_100_25_50', 'test_100_25_75', 'test_100_50_15',\n",
    "            'test_100_50_25', 'test_100_50_50', 'test_100_50_75']\n",
    "print(DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run and collect data\n",
    "CMD_TEMPL = \"../CSP {} {}\"\n",
    "dataset_data = {}\n",
    "\n",
    "\n",
    "def get_answer(lo, hi, filename, f=None):\n",
    "    \"\"\"Get the smallest program answer.\"\"\"\n",
    "    for k_ in range(lo, hi + 1):\n",
    "        cmd = CMD_TEMPL.format(filename, k_)\n",
    "        if f:\n",
    "            cmd += \" -f\"\n",
    "        answer = subprocess.check_output(cmd, shell=True).decode(\"utf-8\").split(\"\\n\")[1]\n",
    "        if answer == \"False\":\n",
    "            continue\n",
    "        return k_\n",
    "\n",
    "datasets_num = len(DATASETS)\n",
    "for num, dataset in enumerate(DATASETS):\n",
    "    print(\"Dataset {} / {} in progress\".format(num + 1, datasets_num))\n",
    "    dataset_metadata = dataset.split(\"_\")\n",
    "    str_len = int(dataset_metadata[1])\n",
    "    str_num = int(dataset_metadata[2])\n",
    "    answer = int(dataset_metadata[3])\n",
    "    dataset_data[num] = {\"answers\": [],\n",
    "                         \"answers_f\": [],\n",
    "                         \"data\": {\"str_len\": str_len,\n",
    "                                  \"str_num\": str_num,\n",
    "                                  \"answer\": answer}}\n",
    "    dataset_dir = os.path.join(DATASETS_DIR, dataset)\n",
    "    contents = os.listdir(dataset_dir)\n",
    "    for fle in contents:\n",
    "        f_path = os.path.join(dataset_dir, fle)\n",
    "        k = get_answer(answer, str_len, f_path)\n",
    "        k_f = get_answer(answer, str_len, f_path, f=True)\n",
    "        dataset_data[num][\"answers\"].append(k)\n",
    "        dataset_data[num][\"answers_f\"].append(k_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare answers with and without F flag\n",
    "all_answers = []\n",
    "all_f_answers = []\n",
    "for k, v in dataset_data.items():\n",
    "    all_answers.extend(v[\"answers\"])\n",
    "    all_f_answers.extend(v[\"answers_f\"])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(all_answers, all_f_answers, s=3)\n",
    "ax.set_xlabel(\"Answer without F flag\")\n",
    "x = linspace(*ax.get_xlim())\n",
    "ax.set_ylabel(\"Answer with F flag\")\n",
    "ax.plot(x, x)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in dataset_data.items():\n",
    "    v[\"errors\"] = [a - v[\"data\"][\"answer\"] for a in v[\"answers\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the error\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "rows = 1\n",
    "cols = 8\n",
    "to_plot = []\n",
    "titles = []\n",
    "\n",
    "perc_errors = []\n",
    "answers = []\n",
    "ax = fig.add_subplot(rows, cols, num)\n",
    "for num, (k, v) in enumerate(dataset_data.items(), 1):\n",
    "    # ax = fig.add_subplot(rows, cols, num)\n",
    "    ans = v[\"data\"][\"answer\"]\n",
    "    ans_arr = [ans for _ in range(len(v[\"errors\"]))]\n",
    "    answers.extend(ans_arr)\n",
    "    perc_error = [e / ans * 100 for e in v[\"errors\"]]\n",
    "    perc_errors.extend(perc_error)\n",
    "    to_plot.append(perc_error)\n",
    "    title = \"{} {} {}\".format(v[\"data\"][\"str_len\"], v[\"data\"][\"str_num\"], ans)\n",
    "    titles.append(title)\n",
    "    # ax.set_title(title)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "bp = ax.boxplot(to_plot)\n",
    "ax.set_ylabel(\"Error\")\n",
    "ax.set_xlabel(\"Dataset\")\n",
    "ax.set_xticklabels(titles, rotation=45, fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 8))\n",
    "plt.scatter(answers, perc_errors)\n",
    "plt.xlabel(\"Answer\")\n",
    "plt.ylabel(\"Error percent\")\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
